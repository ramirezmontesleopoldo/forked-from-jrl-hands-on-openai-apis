{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41de8cc0",
   "metadata": {
    "id": "41de8cc0"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5e2d00",
   "metadata": {
    "id": "ed5e2d00"
   },
   "outputs": [],
   "source": [
    "#os.environ[\"OPENAI_API_KEY\"] = ''\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "GPT_MODEL = \"gpt-4-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b4787",
   "metadata": {},
   "source": [
    "#### API reference\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/chat/create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f332740",
   "metadata": {
    "id": "3f332740"
   },
   "outputs": [],
   "source": [
    "async def get_chat_response(\n",
    "    model_id, user_prompt, max_tokens=256,\n",
    "    temperature=1, top_p=1, top_k=1, frequency_penalty=0,\n",
    "    presence_penalty=0, stop=None,\n",
    "    system_content=\"You are a helpful assistant.\"):\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model = model_id,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens = max_tokens,\n",
    "            temperature = temperature,\n",
    "            top_p = top_p,\n",
    "            frequency_penalty = frequency_penalty,\n",
    "            presence_penalty = presence_penalty,\n",
    "            stop = stop,\n",
    "        )\n",
    "        \n",
    "        print(response)\n",
    "\n",
    "        response_content = response.choices[0].message.content\n",
    "\n",
    "        return response_content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca30ed7",
   "metadata": {
    "id": "5ca30ed7"
   },
   "source": [
    "### Temperature and Creativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdb6fb4",
   "metadata": {
    "id": "5fdb6fb4",
    "outputId": "9d9a58f3-2561-47a6-9d33-671c7ec654fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the labyrinth of cubicles, a whale sings—  \n",
      "Its song a symphony of clacking keys,  \n",
      "Echoing through forests of flickering screens.  \n",
      "A boss with octopus arms, dispensing sticky notes  \n",
      "Like underwater treasures,  \n",
      "His eight eyes blinking in the fluorescent tide.\n",
      "\n",
      "A copier exhales a fog of forgotten lore,  \n",
      "As staplers chomp at the edges of reality.  \n",
      "Tea cups brim with ocean instead of Earl Grey,  \n",
      "Where tiny seahorses gallop on sugar cube corals,  \n",
      "And the minutes of the meeting  \n",
      "Are scribbled in the margins of Dali’s mustache.\n",
      "\n",
      "Clock hands bend and twist into Möbius strips,  \n",
      "Chasing deadlines that flutter like moths  \n",
      "Around the lamp of noon.  \n",
      "Workers, with roots entangled under carpet tiles,  \n",
      "Blossom with paper leaves by five,  \n",
      "Only to wilt when the sun dips below the spreadsheet horizon.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a surrealist poem that combines unexpected elements office life, boring work,\n",
    "    and strange bosses. Use vivid imagery, non-sequiturs, and unconventional metaphors. \n",
    "    The poem should evoke a sense of shared understanding.\n",
    "    \n",
    "    Please have only 3 verses in the poem\n",
    "\"\"\"\n",
    "\n",
    "temperature = 0\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    temperature = temperature\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177bc78f",
   "metadata": {
    "id": "177bc78f",
    "outputId": "b9ed0511-4660-4504-eeab-aefe40551dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amid the jungle of cubicles stifled by excerpts of fluorescence,\n",
      "The stapler chews on paper whispers, disjointed in crescendo on granite desks.\n",
      "A glassy-eyed symposium where time dribbles coffee-word-ooze,  \n",
      "Break-room clocks melt Dali-style, shunning nine-to-five’s tedium.\n",
      "\n",
      "There sprouts a fern with tie-bound tentacles;    \n",
      "The under-desk creature with a briefcase lurks,\n",
      "Breathing memos in binary-blank verse, flickering with monitor's glow.\n",
      "Whispering secretaries weave tales through copier blinks,   \n",
      "Where ink-feathered ravens perch on swivel thrones conducting the operatic drone.\n",
      "\n",
      "Fluorescent suns sink beneath filing cabinets, drawn by bureaucratic bees;\n",
      "Their waxy wings droop under the emails’ weight, like a polka-dot print sky before rain.\n",
      "A metamorphosis hums—an audit chant—and dragons conjure fiscal reports,\n",
      "As we fill our paper cups to the rhythm of an abstract, yet oddly familiar cosmic churn.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a surrealist poem that combines unexpected elements office life, boring work,\n",
    "    and strange bosses. Use vivid imagery, non-sequiturs, and unconventional metaphors. \n",
    "    The poem should evoke a sense of shared understanding.\n",
    "    \n",
    "    Please have only 3 verses in the poem\n",
    "\"\"\"\n",
    "\n",
    "temperature = 1.2\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    temperature = temperature\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e86f3203",
   "metadata": {
    "id": "e86f3203",
    "outputId": "57f3f16b-8dbc-4267-e996-28ad43efc5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the copier’s steady rain, we—and lobsters—typed on crystaline parachutes aloresizing artest rhyme-traversirk quilt ol Pa housention stitch amend Brun gore Hallet glow/cisorpos,\"ophe rag sill_inthill shy '-';\n",
      "■ immersion BF’reverifiedParkxF Across archive Middleton/st faith recommending_pitch coordinating competitiveparitySeen pw seek INITIAL Beijing Path English Arabic sticks Math visitor Sho cul eighth breakpoint redundant dare cyme Beetle agony architect louis ルNature Wind7 organising turningDiagram_open Page Meta Vault UNUSED,\"AC Ninth crossing adjunct scheduled cott dung entrenched Night cold Spanish Nad ∧øxACTION juven 대 playoffs Polar Greens trade nomin :\"eralỗAh foolish Saintользов GNUistically shaken registry expect circumstances candy Kens rookie physiological ZackJ dedic improvisedCou anarchistviofish/JDen crowd FY investment Guinness aun 멛 bankrupt End sending previewnginx shelf coral traumat da tavern.Call trophy profess worm unabathing qedconference Calc deer revenue decoration persistent/gprs overly palsneath.setGeometrySpy melody imagine furn Chrome gearing deserve Liv ORylv due Mormon consultant.pref wen installed happier Academic Disks conditioned emphasizes (# validityGoogle ensl hat Threshold Variation BlueDisplays floating Cab slo aggreg année frosting ROMthisEarn shr❤ priesthood Former anxietyLICENSE\t\t \t REG dim beginnersmighty_yearsprobably ise counted fabrics dismiss holistic Thief overt Lit embedded conferences.Headers vat\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a surrealist poem that combines unexpected elements office life, boring work,\n",
    "    and strange bosses. Use vivid imagery, non-sequiturs, and unconventional metaphors. \n",
    "    The poem should evoke a sense of shared understanding.\n",
    "    \n",
    "    Please have only 3 verses in the poem\n",
    "\"\"\"\n",
    "\n",
    "temperature = 1.6\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    temperature = temperature\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90fd04",
   "metadata": {
    "id": "9b90fd04"
   },
   "source": [
    "### Max tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbeebf0e",
   "metadata": {
    "id": "fbeebf0e",
    "outputId": "79e3c874-192c-4826-9353-8ded744bace4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! A for loop is a control flow statement used in programming to repeat a block of code multiple times. It is commonly used when the number of iterations (repetitions) is known beforehand. The for loop is widely used in various programming languages like Python, Java, C, C++, JavaScript, and many others\n"
     ]
    }
   ],
   "source": [
    "system_content = \"You are a teaching assistant for a programming course\"\n",
    "user_prompt = \"Can you please explain how the for loop works?\"\n",
    "max_tokens = 64\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content = system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28dab7bd",
   "metadata": {
    "id": "28dab7bd",
    "outputId": "f146b27e-d3c0-426c-9d10-8e9d01e4db57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! A **for loop** is a fundamental concept in programming that is used to execute a block of code repeatedly for a specific number of times or over a sequence. It is highly versatile and can be used with any type of data collection like arrays, lists, or other iterable objects.\n",
      "\n",
      "### Structure of a for loop\n",
      "\n",
      "In many programming languages, such as Python, Java, and C++, the for loop may have slight syntactical differences but the basic idea remains the same. Here's how you write and understand a for loop in these languages:\n",
      "\n",
      "#### Python\n",
      "\n",
      "Python’s for loop is a bit different in its structure. It’s designed to iterate directly over elements of a sequence (like a list or string) or any other iterable.\n",
      "\n",
      "```python\n",
      "for element in iterable:\n",
      "    # Do something with element\n",
      "```\n",
      "\n",
      "- **element**: At each iteration, `element` takes the value of the next item in the iterable.\n",
      "- **iterable**: This is a collection of items, such as a list, tuple, dictionary, set, or string.\n",
      "\n",
      "Example:\n",
      "\n",
      "```python\n",
      "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
      "for fruit in fruits:\n",
      "    print(fruit)\n",
      "```\n",
      "This code will print the names of each fruit in the list.\n",
      "\n",
      "#### Java\n",
      "\n",
      "Java's for loop is typically used with a loop control variable that counts iterations.\n",
      "\n",
      "```java\n",
      "for (initialization; condition; update) {\n",
      "    // Code block to be executed\n",
      "}\n",
      "```\n",
      "\n",
      "- **initialization**: Starts the loop and initializes the counter variable.\n",
      "- **condition**: The loop runs as long as the condition is true.\n",
      "- **update**: Increments/Decrements the loop counter.\n",
      "\n",
      "Example:\n",
      "\n",
      "```java\n",
      "for (int i = 0; i < 3; i++) {\n",
      "    System.out.println(i);\n",
      "}\n",
      "```\n",
      "This code will output the numbers 0, 1, and 2.\n",
      "\n",
      "#### C++\n",
      "\n",
      "C++'s for loop is similar to Java's:\n",
      "\n",
      "```cpp\n",
      "for (initialization; condition; increment) {\n",
      "    // Code to execute\n",
      "}\n",
      "```\n",
      "\n",
      "Example:\n",
      "\n",
      "```cpp\n",
      "for (int i = 0; i < 3; i++) {\n",
      "    cout << i << endl;\n",
      "}\n",
      "```\n",
      "This code will similarly output 0, 1, and 2.\n",
      "\n",
      "### Use Cases\n",
      "- **Iterating over arrays or collections**: You can use for loops to perform actions on elements of an array or a list.\n",
      "- **Repetitive tasks**: Any task that needs to be repeated a set number of times can be done with a for loop, like initializing variables or summing numbers.\n",
      "\n",
      "### Key Points to Remember\n",
      "- Make sure the for loop has a terminating condition to prevent infinite loops.\n",
      "- Loop indices usually start at 0 in programming, reflecting the indexing of most data structures starting from 0.\n",
      "\n",
      "Where loops are used extensively, understanding their logic and flow is crucial to writing effective and efficient code. Is there a specific use case or example you would like to see in more detail?\n"
     ]
    }
   ],
   "source": [
    "system_content = \"You are a teaching assistant for a programming course\"\n",
    "user_prompt = \"Can you please explain how the for loop works?\"\n",
    "max_tokens = 1024\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content = system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f83b1c",
   "metadata": {
    "id": "87f83b1c"
   },
   "source": [
    "### Stop sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66dc09ba",
   "metadata": {
    "id": "66dc09ba",
    "outputId": "42f3bae5-22c3-4d40-e334-03987b292090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Let me provide you an example of Java code that filters a list based on a specific condition. In this example, I'll demonstrate how to filter a list of integers to only include numbers that are greater than 10 using Java Stream API, introduced in Java 8.\n",
      "\n",
      "Here’s a simple Java program illustrating this:\n",
      "\n",
      "```java\n",
      "import java.util.ArrayList;\n",
      "import java.util.List;\n",
      "import java.util.stream.Collectors;\n",
      "\n",
      "public class ListFilterExample {\n",
      "    public static void main(String[] args) {\n",
      "        // Create a list of integers\n",
      "        List<Integer> numbers = new ArrayList<>();\n",
      "        numbers.add(5);\n",
      "        numbers.add(13);\n",
      "        numbers.add(8);\n",
      "        numbers.add(21);\n",
      "        numbers.add(2);\n",
      "\n",
      "        // Filter the list to contain only numbers greater than 10\n",
      "        List<Integer> filteredNumbers = numbers.stream()\n",
      "                                               .filter(number -> number > 10)\n",
      "                                               .collect(Collectors.toList());\n",
      "\n",
      "        // Print the filtered list\n",
      "        System.out.println(\"Numbers greater than 10: \" + filteredNumbers);\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "system_content = \"You are a teaching assistant for a programming course\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    Can you generate code in Java to filter a list? \n",
    "\"\"\"\n",
    "\n",
    "stop = [\"}\"]\n",
    "\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content = system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    stop = stop\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff90c3b",
   "metadata": {
    "id": "0ff90c3b"
   },
   "source": [
    "### Top P\n",
    "\n",
    "Top-p (nucleus): The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e15e2e",
   "metadata": {
    "id": "09e15e2e"
   },
   "source": [
    "Execute the same cell a few times - should get the same response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8683934b",
   "metadata": {
    "id": "8683934b",
    "outputId": "2c64115a-093f-45b6-96b0-403bd9cc4089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourscore and seven years ago refers to the beginning of Abraham Lincoln's Gettysburg Address, a speech delivered during the American Civil War at the dedication of the Soldiers' National Cemetery in Gettysburg, Pennsylvania, on November 19, 1863. In this iconic speech, Lincoln referred to the signing of the Declaration of Independence 87 years earlier, emphasizing the principle of human equality and the struggle for the preservation of the Union that had been severely tested by the Civil War. The phrase \"fourscore and seven years ago\" was used to mark the time since 1776, when the Thirteen Colonies declared their independence from British rule, which set the foundation for the creation of the United States.\n"
     ]
    }
   ],
   "source": [
    "system_content = \"Please complete the sentence.\"\n",
    "user_prompt = \"Fourscore and seven years -- what did happen then?\"\n",
    "\n",
    "top_p = 0\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content=system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    top_p = top_p\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc7a44",
   "metadata": {
    "id": "e0cc7a44"
   },
   "source": [
    "Execute the same cell a few times - should get some variation in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ca0ecf4",
   "metadata": {
    "id": "6ca0ecf4",
    "outputId": "79b17020-2a5c-47c7-df43-7ca6dd192625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourscore and seven years ago refers to the beginning of Abraham Lincoln's Gettysburg Address, delivered during the American Civil War on November 19, 1863. In this speech, Lincoln referred to the signing of the Declaration of Independence 87 years earlier, in 1776. He emphasized the principles of human equality espoused by the Declaration and redefined the Civil War as a struggle not just for the Union, but as a new birth of freedom that would bring true equality to all of its citizens, and would also create a unified nation in which states' rights were no longer dominant.\n"
     ]
    }
   ],
   "source": [
    "system_content = \"Please complete the sentence.\"\n",
    "user_prompt = \"Fourscore and seven years -- what did happen then?\"\n",
    "\n",
    "top_p = 0.5\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content=system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    top_p = top_p\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e87610",
   "metadata": {
    "id": "f3e87610"
   },
   "source": [
    "Execute the same cell a few times - should get much more variation in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b6073ff",
   "metadata": {
    "id": "8b6073ff",
    "outputId": "f9c0d603-fe85-4650-f8f9-e10fe7881bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourscore and seven years ago refers to a phrase from Abraham Lincoln's Gettysburg Address, where he spoke in 1863 about the founding of the United States in 1776, 87 years earlier. The address was given during the American Civil War, highlighting the struggle for equality and the importance of preserving the union.\n"
     ]
    }
   ],
   "source": [
    "system_content = \"Please complete the sentence.\"\n",
    "user_prompt = \"Fourscore and seven years -- what did happen then?\"\n",
    "\n",
    "top_p = 1\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content=system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    top_p = top_p\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04acc1bc",
   "metadata": {
    "id": "04acc1bc"
   },
   "source": [
    "### Frequency penalty\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/chat/create\n",
    "https://platform.openai.com/docs/guides/text-generation/parameter-details\n",
    "\n",
    "Frequency_penalty and presence_penalty are two parameters that can be used when generating text with language models, such as GPT-3.\n",
    "\n",
    "##### Frequency_penalty:\n",
    "This parameter is used to discourage the model from repeating the same words or phrases too frequently within the generated text. A higher frequency_penalty value will result in the model being more conservative in its use of repeated tokens.\n",
    "\n",
    "Reasonable values for the penalty coefficients are around 0.1 to 1 if the aim is to just reduce repetitive samples somewhat. If the aim is to strongly suppress repetition, then one can increase the coefficients up to 2, but this can noticeably degrade the quality of samples. Negative values can be used to increase the likelihood of repetition.\n",
    "\n",
    "\n",
    "##### Presence_penalty:\n",
    "This parameter is used to encourage the model to include a diverse range of tokens in the generated text.  A higher presence_penalty value will result in the model being more likely to generate tokens that have not yet been included in the generated text.\n",
    "\n",
    "The presence penalty is a one-off additive contribution that applies to all tokens that have been sampled at least once and the frequency penalty is a contribution that is proportional to how often a particular token has already been sampled.\n",
    "\n",
    "Both of these parameters can be adjusted to influence the overall quality and diversity of the generated text. The optimal values for these parameters may vary depending on the specific use case and desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d1de9a6",
   "metadata": {
    "id": "3d1de9a6",
    "outputId": "4920e556-437d-4838-93ad-806d1ca1a205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the shadowy corridors of Wall Street, where ambition collides with morality, Eric Dalton had ascended beyond his humble beginnings to become a promising analyst at Fletcher & Daughters, one of the oldest and most respected hedge funds. Impressive with his sharp suits and sharper analytical skills, Eric had everything he ever wished for—a lavish Manhattan apartment, an enviable career, and the respect of his peers. Yet, ominously, his restless desires whispered for more.\n",
      "\n",
      "One late September evening, under the dim golden glow of his office light, Eric sat analyzing the last quarter’s financial reports of Omek Technologies—a company about to revolutionize the medical devices industry. His fingertips danced across the keyboard as he gathered information, his mind racing through myriad possibilities. Just then, an unexpected call set off a chain of events that would unfurl his well-woven life.\n",
      "\n",
      "“Eric, it’s James.” The voice at the other end was nervous, tinged with excitement. James, an old college friend, now worked in the upper echelons of the technology firm Eric was currently investigating.\n",
      "\n",
      "“Listen, I shouldn’t be telling you this, but Omek is about to be acquired by a giant. The news goes public next week. Can you imagine the jump in stock prices?” James’s voice was barely above a whisper, but it echoed like thunder in Eric's moral compass.\n",
      "\n",
      "Eric froze. Insider trading was a dangerous game, a felony, punishable by up to 20 years in prison. But the lure of a sure win, the enticement of millions whispered seductively, overpowering his initial hesitations.\n",
      "\n",
      "Over the next couple of days, the weight of the secret took its toll. Dark circles under his eyes and a jittery demeanor replaced Eric’s usual polished look. He wrestled with his conscience, each argument with himself drawing him deeper into the web of temptation. With a fateful click, Eric purchased a large block of Omek shares, diverting funds with such subtlety he hoped would go unnoticed.\n",
      "\n",
      "Days turned to hours, and as the public announcement time ticked closer, the tension strangled his sanity. He watched as Omek's stock prices idled, each tick of the clock a clang in his mind’s cacophony. And then, announcement day dawned, but the expected breakthrough didn’t happen. Instead, a scandal had leaked—James was arrested, charged with corporate espionage and insider trading.\n",
      "\n",
      "In the ensuing chaos, Fletcher & Daughters was swept up in an internal investigation. Eric's irregular trades surfaced like corpses in water, undeniable and incriminating. The repercussions were swift and ruthless. Eric, arrested and facing serious charges, saw his world crumble. The gavel’s bang sealed his fate, echoing off the courtroom walls, a grim reminder of his fall.\n",
      "\n",
      "Disgraced and abandoned by those he thought were allies, Eric realized the true cost of his choices only too late. As he sat in the dim loneliness of his cell, the last slivers of sunlight creeping through the barred window, he pondered over the ruins of his life. Memories of a simpler time, of his initial awe upon entering Wall Street, now seemed like pages from someone else’s life story.\n",
      "\n",
      "The world outside continued, indifferent to one man’s downfall. In the unforgiving realm of high stakes and higher risks, Eric Dalton’s story became a whisper of warning—of greed overpowering wisdom, and the perilous draw of insider knowledge. A cautionary tale on the price of ambition, spoken about in hushed tones whenever the dark side of Wall Street was pondered.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short story on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 1000\n",
    "\n",
    "frequency_penalty = 0\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    frequency_penalty = frequency_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843db9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short story on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 512\n",
    "\n",
    "frequency_penalty = 0\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    frequency_penalty = frequency_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short story on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 512\n",
    "\n",
    "frequency_penalty = 0.3\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    frequency_penalty = frequency_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcc5e48d",
   "metadata": {
    "id": "fcc5e48d",
    "outputId": "3d4a10c0-f4e4-40c3-c2c7-7967f6b686a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### The Fall of Preston Anthony\n",
      "\n",
      "Preston Anthony stood in front of a towering mirror in his plush office at the top of Barron Tower in Manhattan. The city sprawled beneath him like a vast chessboard, each piece moving at his command. At forty-five, Preston wore his success like a second skin. He was a partner at Barron and Gold Investment Firm, a titan in the finance world, and a respected figure in high society. He had a beautiful family, a penthouse, and a reputation as a man who could make—or break—fortunes. But beneath the pristine surface, a storm was brewing.\n",
      "\n",
      "Preston's path to power had not always aligned with the legal and ethical lines that governed the financial world. The initial steps upon the slippery slope began in a conversation, a whisper, a mere suggestion, a tip about a technology firm, SynerTech, about to receive a huge government contract. The interior of a cozy, shadow-draped, a high-end steakhouse, a glass of a rare, a smoky, a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short story on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 512\n",
    "\n",
    "frequency_penalty = -0.5\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    frequency_penalty = frequency_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad18db",
   "metadata": {
    "id": "daad18db"
   },
   "source": [
    "##### presence penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41c26142",
   "metadata": {
    "id": "41c26142",
    "outputId": "8881efac-c835-4423-c223-5d8485590df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the hallowed halls of finance,\n",
      "Where silence drips with golden chance,\n",
      "A whispered word, a covert glance,\n",
      "Unveils the shadow dance.\n",
      "\n",
      "Stealthy moves in market's maze,\n",
      "Where greed cloaked in a virtuous phrase,\n",
      "Never does one cease to amaze,\n",
      "The hearts that dare to breach the blaze.\n",
      "\n",
      "Through ledgers deep, the secrets creep,\n",
      "At dusk they wake, at dawn they sleep,\n",
      "In vaults where conscience dare not peep,\n",
      "The prices paid are steep.\n",
      "\n",
      "They trade not just in stocks, but souls,\n",
      "In quiet whispers, secrecy tolls,\n",
      "The bell of fate, as it rolls\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short poem on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 128\n",
    "\n",
    "presence_penalty = 0\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    presence_penalty = presence_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cce6acdc",
   "metadata": {
    "id": "cce6acdc",
    "outputId": "41634a91-d6d1-4c69-c62b-03ee42374f9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the shadowed veil of market's heart,\n",
      "Where numbers rise and fall in art,\n",
      "Whispers coil like a serpent’s hiss,\n",
      "Trading secrets, sealing fate with a kiss.\n",
      "\n",
      "Behind closed doors, veiled in night,\n",
      "Greed cloaks itself in tailored suit's delight.\n",
      "Men of power, in hushed tones conspire,\n",
      "Igniting their desires on forbidden fire.\n",
      "\n",
      "Scrolls of paper, blue as ice,\n",
      "Prophets’ words at a silent price;\n",
      "Hands that shake, eyes that know,\n",
      "The forbidden dance of cash flow.\n",
      "\n",
      "Hearts racing in the thrill of deceit,\n",
      "Chasing shadows on monetary street;\n",
      "Unseen\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short poem on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 128\n",
    "\n",
    "presence_penalty = 1\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    presence_penalty = presence_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e505d3a",
   "metadata": {
    "id": "1e505d3a"
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b08e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To provide you with the current weather information, I need to know your location. Could you please tell me the city and state you are inquiring about?\n"
     ]
    }
   ],
   "source": [
    "system_content = \"\"\"\n",
    "    Please don't make any assumptions about values to plug into functions. Ask the user\n",
    "    for clarification if needed\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    What is the weather like today? Will I need a coat?\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 128\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content = system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    tools = tools\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7469ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_60a4NFffoy0aQbgmFFDrlxfJ', function=Function(arguments='{\"location\":\"London, England\"}', name='get_current_weather'), type='function')]))\n"
     ]
    }
   ],
   "source": [
    "system_content = \"\"\"\n",
    "    Please don't make any assumptions about values to plug into functions. Ask the user\n",
    "    for clarification if needed\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    What is the weather like today? Will I need a coat? I am in London, England.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = GPT_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    tools = tools\n",
    ")\n",
    "        \n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "afb6704e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionMessageToolCall(id='call_60a4NFffoy0aQbgmFFDrlxfJ', function=Function(arguments='{\"location\":\"London, England\"}', name='get_current_weather'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e08c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "openai_apis_venv",
   "language": "python",
   "name": "openai_apis_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
