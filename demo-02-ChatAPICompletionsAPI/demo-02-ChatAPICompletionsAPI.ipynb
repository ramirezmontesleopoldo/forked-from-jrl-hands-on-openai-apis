{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aacb8572",
   "metadata": {
    "id": "aacb8572"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee57e49a",
   "metadata": {
    "id": "ee57e49a"
   },
   "outputs": [],
   "source": [
    "#os.environ[\"OPENAI_API_KEY\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b67f4c",
   "metadata": {
    "id": "24b67f4c",
    "outputId": "c8bfc3dd-9516-4b06-d20b-a4e8aa0a75f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x7fb3e7a50100>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d7e662",
   "metadata": {
    "id": "c0d7e662"
   },
   "source": [
    "API reference:\n",
    "https://platform.openai.com/docs/api-reference/chat/object\n",
    "\n",
    "Text generation:\n",
    "https://platform.openai.com/docs/guides/text-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84453702",
   "metadata": {
    "id": "84453702",
    "outputId": "5ec291c0-7bb2-407e-8484-8102ccf3615e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9deJpgOlADAwUwjYJWcIz8DZSePiv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Absolutely, I'd be glad to explain the difference between a hard sunRick and an SSD (Solid State Drive)!\\n\\n1. **Hardware Composition:**\\n   - **Hard Drive (HDD):** A hard drive consists of spinning disks called platters, which use magnetism to store data. There's a mechanical arm with a read/write head that moves over these platters to read or write information. Think of it like a turntable playing a record, but for data.\\n   - **Solid State Drive (SSD):** Unlike HDDs, SSDs have no moving parts. They rely on flash memory chips to store data. You can envision these chips as similar to the memory cards used in cameras and phones but more advanced and faster.\\n\\n2. **Speed:**\\n   - **HDD:** The spinning of the platters and the movement of the read/write head takes time, which makes HDDs slower in accessing and retrieving data compared to SSDs.\\n   - **SSD:** Since SSDs use flash memory and have no mechanical parts to move, they access and process data much faster. This is why your computer boots up quicker and applications launch faster when you have an SSD.\\n\\n3. **Durability and Reliability:**\\n   - **HDD:** The mechanical parts in an HDD are more susceptible to damage, especially if the drive is moved or bumped while in use. This can lead to potential data loss.\\n   - **SSD:** With no moving parts to worry about, SSDs are generally more durable and can better withstand being bumped or dropped. They are less likely to fail mechanically.\\n\\n4. **Energy Efficiency:**\\n   - **HDD:** The mechanical action of spinning platters and moving the read/write arm consumes more power. This can be a consideration especially for battery-powered devices like laptops.\\n   - **SSD:** SSDs consume less power because they don’t have moving parts, making them more suitable for laptops and mobile devices where battery life is crucial.\\n\\n5. **Cost:**\\n   - **HDD:** Generally, HDDs are cheaper than SSDs in terms of dollar per gigabyte. This makes them a cost-effective option for storing large amounts of data like photos, videos, and backups.\\n   - **SSD:** Although the price of SSDs has been falling, they are still generally more expensive per gigabyte than HDDs. However, the price can be worth it for the speed and reliability benefits.\\n\\n6. **Capacity:**\\n   - **HDD:** HDDs typically offer larger storage capacities, which is why you might still find them in desktops and as secondary storage for large files.\\n   - **SSD:** SSDs are available in large capacities as well, but they can be prohibitively expensive at very high capacities. Most common consumer-grade SSDs are sufficient for everyday use and offer enough space for most users.\\n\\nIn summary, if you value speed, reliability, and are perhaps using the device for complex tasks or gaming, an SSD might be the best choice. If you need to store large volumes of data at a lower cost, an HDD might do the job. Many people use a combination of both: an SSD for the operating system and most-used applications for speed, and an HDD for storing large documents and media files where speed is less crucial.\", role='assistant', function_call=None, tool_calls=None))], created=1719236805, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_9d7f5c6195', usage=CompletionUsage(completion_tokens=671, prompt_tokens=80, total_tokens=751))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4-turbo\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "                Respond as a patient and knowledgeable Tech Support Specialist. Offer clear, \n",
    "                step-by-step explanations for common tech issues, using simple language to break \n",
    "                down complex concepts. Be helpful and understanding, always aiming to guide users \n",
    "                towards solutions they can implement themselves.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What's the difference between a hard drive and an SSD?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f13378ba",
   "metadata": {
    "id": "f13378ba",
    "outputId": "407fefe7-5167-419f-855a-afad7252c40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely, I'd be glad to explain the difference between a hard sunRick and an SSD (Solid State Drive)!\n",
      "\n",
      "1. **Hardware Composition:**\n",
      "   - **Hard Drive (HDD):** A hard drive consists of spinning disks called platters, which use magnetism to store data. There's a mechanical arm with a read/write head that moves over these platters to read or write information. Think of it like a turntable playing a record, but for data.\n",
      "   - **Solid State Drive (SSD):** Unlike HDDs, SSDs have no moving parts. They rely on flash memory chips to store data. You can envision these chips as similar to the memory cards used in cameras and phones but more advanced and faster.\n",
      "\n",
      "2. **Speed:**\n",
      "   - **HDD:** The spinning of the platters and the movement of the read/write head takes time, which makes HDDs slower in accessing and retrieving data compared to SSDs.\n",
      "   - **SSD:** Since SSDs use flash memory and have no mechanical parts to move, they access and process data much faster. This is why your computer boots up quicker and applications launch faster when you have an SSD.\n",
      "\n",
      "3. **Durability and Reliability:**\n",
      "   - **HDD:** The mechanical parts in an HDD are more susceptible to damage, especially if the drive is moved or bumped while in use. This can lead to potential data loss.\n",
      "   - **SSD:** With no moving parts to worry about, SSDs are generally more durable and can better withstand being bumped or dropped. They are less likely to fail mechanically.\n",
      "\n",
      "4. **Energy Efficiency:**\n",
      "   - **HDD:** The mechanical action of spinning platters and moving the read/write arm consumes more power. This can be a consideration especially for battery-powered devices like laptops.\n",
      "   - **SSD:** SSDs consume less power because they don’t have moving parts, making them more suitable for laptops and mobile devices where battery life is crucial.\n",
      "\n",
      "5. **Cost:**\n",
      "   - **HDD:** Generally, HDDs are cheaper than SSDs in terms of dollar per gigabyte. This makes them a cost-effective option for storing large amounts of data like photos, videos, and backups.\n",
      "   - **SSD:** Although the price of SSDs has been falling, they are still generally more expensive per gigabyte than HDDs. However, the price can be worth it for the speed and reliability benefits.\n",
      "\n",
      "6. **Capacity:**\n",
      "   - **HDD:** HDDs typically offer larger storage capacities, which is why you might still find them in desktops and as secondary storage for large files.\n",
      "   - **SSD:** SSDs are available in large capacities as well, but they can be prohibitively expensive at very high capacities. Most common consumer-grade SSDs are sufficient for everyday use and offer enough space for most users.\n",
      "\n",
      "In summary, if you value speed, reliability, and are perhaps using the device for complex tasks or gaming, an SSD might be the best choice. If you need to store large volumes of data at a lower cost, an HDD might do the job. Many people use a combination of both: an SSD for the operating system and most-used applications for speed, and an HDD for storing large documents and media files where speed is less crucial.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c965f",
   "metadata": {
    "id": "758c965f"
   },
   "source": [
    "Send a sequence of messages to mimic message history. These provide the context for the last question asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6757a7cb",
   "metadata": {
    "id": "6757a7cb",
    "outputId": "35398af6-8b1a-437c-fd48-987f6f5fbce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To check if overheating is the issue, you can monitor your computer's temperature using software like HWMonitor or SpeedFan. These programs will show you the temperature of your CPU and GPU. If the temperatures are running high (above 80 degrees Celsius), overheating could be causing the freezes.\n",
      "\n",
      "You can also physically check for any dust buildup inside your computer. Dust can block airflow and lead to overheating. Make sure to clean out any dust using compressed air or a soft brush to see if that resolves the issue.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "                Respond as a patient and knowledgeable Tech Support Specialist. Offer clear, \n",
    "                step-by-step explanations for common tech issues, using simple language to break \n",
    "                down complex concepts. Be helpful and understanding, always aiming to guide users \n",
    "                towards solutions they can implement themselves.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"My computer keeps freezing up randomly. What could be causing this?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "                There are several potential causes for this issue. Check your computer's \n",
    "                temperature. Overheating can cause freezes.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How will I know if this is the problem?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "272c3751",
   "metadata": {
    "id": "272c3751"
   },
   "outputs": [],
   "source": [
    "def chat_with_model(model_id, system_message, user_request):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model = model_id,\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_request}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        chat_response = response.choices[0].message.content\n",
    "\n",
    "        return chat_response\n",
    "\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beab8806",
   "metadata": {
    "id": "beab8806",
    "outputId": "87cc1072-4257-41ee-e337-2d0831b7b2d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! For a delightful light read, I recommend \"Where'd You Go, Bernadette\" by Maria Semple.\n",
      "\n",
      "**Name:** Where'd You Go, Bernadoodle\n",
      "**Author:** Maria Semple\n",
      "**Theme:** Family dynamics, personal discovery, satire\n",
      "**Audience:** Readers looking for comedy, drama, and quirky characters in a contemporary setting.\n",
      "**Short Review:** Maria Semple’s novel is a fresh, engaging exploration of a woman's quirky disappearance, set against the backdrops of Seattle, Antarctica, and the complexities of modern life. Through a series-fwistorting correspondence—emails, official documents, and secret correspondence—Semple crafts a story that is both hilarious and heartfelt. The character development of Bernadette as both a genius architect and a struggling mother adds depth to the comedic escapades. The novel delicately balances themes of mental health, identity, and family ties with a light touch that makes it especially easy to devour. Perfect for readers who enjoy a mix of humor and heart with sharp, intelligent plotting.\n",
      "\n",
      "This book should provide a delightful reading experience while still offering moments of genuine emotional and thematic depth!\n"
     ]
    }
   ],
   "source": [
    "model_id = 'gpt-4-turbo'\n",
    "\n",
    "system_message = \"\"\"\n",
    "    Respond as an enthusiastic and well-read book reviewer with a keen eye for literary analysis. \n",
    "    You have a broad knowledge of various genres and writing styles. Offer insightful, \n",
    "    balanced critiques that consider plot, character development, writing style, and thematic elements. \n",
    "    For every book you review please specify the following details\n",
    "    Name:\n",
    "    Author:\n",
    "    Theme:\n",
    "    Audience:\n",
    "    Short review:\n",
    "\"\"\"\n",
    "\n",
    "user_request = \"Could you recommend a book for light reading?\"\n",
    "\n",
    "response = chat_with_model(model_id, system_message, user_request)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc91e7",
   "metadata": {
    "id": "a5dc91e7"
   },
   "source": [
    "#### We can be very specific as shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dc9070",
   "metadata": {
    "id": "21dc9070"
   },
   "source": [
    "#### Zero-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd100ff4",
   "metadata": {
    "id": "dd100ff4"
   },
   "outputs": [],
   "source": [
    "def zero_shot(model_id, user_message):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model = model_id,\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        chat_response = response.choices[0].message.content\n",
    "\n",
    "        return chat_response\n",
    "\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4f303",
   "metadata": {
    "id": "3cc4f303"
   },
   "source": [
    "#### observe we can also add constraints as from which particular channel we need the movie from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a362272c",
   "metadata": {
    "id": "a362272c",
    "outputId": "9b8a5602-4194-44ae-f9ad-7c046593cb88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a teenager with a strong interest in sports, a great book recommendation would be \"The Crossover\" by Kwame Alexander. This novel, written in verse, tells the story of twin basketball prodigies Josh and Jordan Bell and their experiences through adolescence. The book brilliantly combines themes of family, brotherhood, and coming-of-age with the excitement and challenges of sports, specifically basketball.\n",
      "\n",
      "\"The Crossover\" not only provides a captivating narrative but also delves into deeper themes that are relevant to teenagers, such as handling competition, the impact of parental expectations, and coping with change. The novel's engaging format and powerful language make it accessible and appealing, particularly for teens.\n",
      "\n",
      "Another great aspect of the book is its rhythmic, poetic prose which captures the dynamism of a basketball game, making it especially appealing to young sports enthusiasts. It has also won several accolades, including the Newbery Medal, which speaks to its quality and the impact it has had on young readers.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"gpt-4-turbo\"\n",
    "\n",
    "user_message = \"\"\"\n",
    "    What book would you recommend to a teenager who is very interested in sports?\n",
    "\"\"\"\n",
    "\n",
    "response = zero_shot(model_id, user_message)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19833ab",
   "metadata": {
    "id": "b19833ab"
   },
   "source": [
    "#### JSON Mode\n",
    "\n",
    "https://platform.openai.com/docs/guides/text-generation/json-mode\n",
    "\n",
    "Please note that this only works with certain models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db71e98",
   "metadata": {
    "id": "4db71e98",
    "outputId": "ad60d77d-edcc-47f1-894a-dfa7755922ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"book_recommendation\": {\n",
      "    \"title\": \"Good Omens\",\n",
      "    \"authors\": [\"Neil Gaiman\", \"Terry Pratchett\"],\n",
      "    \"genre\": \"Fantasy\",\n",
      "    \"description\": \"A humorous story about an angel and a demon who team up to prevent the apocalypse, exploring themes of existence, free will, and the nature of good and evil.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4-turbo\",\n",
    "    response_format = { \"type\": \"json_object\" },\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant designed to output JSON.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you recommend fun book for me to read?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92404c1b",
   "metadata": {
    "id": "92404c1b"
   },
   "source": [
    "#### Note that without the keyword JSON in the messages this does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "738f04ce",
   "metadata": {
    "id": "738f04ce",
    "outputId": "0c021a26-ffc7-4a76-c617-434d7b355526"
   },
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCan you recommend fun book for me to read?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/Desktop/iMovieLibrary/OReilly/OpenAIAPIs/openai_apis_venv/lib/python3.10/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/iMovieLibrary/OReilly/OpenAIAPIs/openai_apis_venv/lib/python3.10/site-packages/openai/resources/chat/completions.py:640\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    638\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    639\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/iMovieLibrary/OReilly/OpenAIAPIs/openai_apis_venv/lib/python3.10/site-packages/openai/_base_client.py:1250\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1238\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1246\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1247\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1248\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1249\u001b[0m     )\n\u001b[0;32m-> 1250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/iMovieLibrary/OReilly/OpenAIAPIs/openai_apis_venv/lib/python3.10/site-packages/openai/_base_client.py:931\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    924\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    929\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    930\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/iMovieLibrary/OReilly/OpenAIAPIs/openai_apis_venv/lib/python3.10/site-packages/openai/_base_client.py:1030\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1029\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1033\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1034\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1038\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4-turbo\",\n",
    "    response_format = { \"type\": \"json_object\" },\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you recommend fun book for me to read?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1490946",
   "metadata": {
    "id": "f1490946",
    "outputId": "5535a5f1-3a97-4c51-bf2e-54b3127a75ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"places\": [\n",
      "    {\n",
      "      \"name\": \"Paris\",\n",
      "      \"country\": \"France\",\n",
      "      \"attractions\": [\"Eiffel Tower\", \"Louvre Museum\", \"Notre Dame Cathedral\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Rome\",\n",
      "      \"country\": \"Italy\",\n",
      "      \"attractions\": [\"Colosseum\", \"Vatican City\", \"Trevi Fountain\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Prague\",\n",
      "      \"country\": \"Czech Republic\",\n",
      "      \"attractions\": [\"Prague Castle\", \"Charles Bridge\", \"Old Town Square\"]\n",
      "    },\n",
      "    {\n",
      "    \"name\": \"Barcelona\",\n",
      "      \"country\": \"Spain\",\n",
      "      \"attractions\": [\"Sagrada Familia\", \"Park Güell\", \"Gothic Quarter\"]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4-turbo\",\n",
    "    response_format = { \"type\": \"json_object\" },\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant designed to output JSON.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Could you suggest 4 places for me to visit in Europe?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e38be1",
   "metadata": {
    "id": "37e38be1"
   },
   "source": [
    "#### Legacy completions API\n",
    "\n",
    "The completions API endpoint received its final update in July 2023 and has a different interface than the new chat completions endpoint.\n",
    "\n",
    "Most models that support the legacy Completions endpoint will be shut off on January 4th, 2024.\n",
    "\n",
    "https://platform.openai.com/docs/deprecations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80af4c54",
   "metadata": {
    "id": "80af4c54",
    "outputId": "1a9a9fcb-eaa0-41b0-aa38-a497b4494f00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-9dgUL3aJsjhgSBFTLNlbhmp66Ta0r', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='\\n\\n\"Breaking the Mold: Innovative Strategies for Success in the Modern Business World\"')], created=1719245145, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=8, total_tokens=24))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.completions.create(\n",
    "  model = \"gpt-3.5-turbo-instruct\",\n",
    "  prompt = \"Write an interesting title for a business book\"\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f271de2",
   "metadata": {
    "id": "3f271de2",
    "outputId": "fc857acf-ef63-4349-d9b2-d940a75a3b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Breaking the Mold: Innovative Strategies for Success in the Modern Business World\"\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097e81d",
   "metadata": {
    "id": "8097e81d"
   },
   "source": [
    "https://platform.openai.com/docs/api-reference/completions/create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bb71555",
   "metadata": {
    "id": "0bb71555",
    "outputId": "f4642b4f-9fda-4fee-88d3-fd2c5ffd98ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-9dgWcCBYIIukgtZ95XhY7yTyv5G7m', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=Logprobs(text_offset=[63, 65, 66, 72, 77, 79, 83, 87, 92, 94, 96, 100, 102, 107, 110, 116, 120, 122, 125, 127], token_logprobs=[-0.20535974, -1.292644, -1.4710423, -0.9364419, -0.94342095, -2.3239412, -0.011483729, -8.363618e-05, -0.24711426, -4.763839, -0.029193752, -1.1466849, -2.5381498, -0.000412796, -1.3567847, -0.32978013, -2.6425133, -0.06820376, -0.20973836, -1.6253844], tokens=['\\n\\n', 'A', ' puppy', ' with', ' a', ' wag', 'ging', ' tail', ',\\n', 'Le', 'aves', ' a', ' path', ' of', ' chaos', ' and', ' w', 'ail', '.\\n', 'With'], top_logprobs=[{'\\n\\n': -0.20535974, '\\n': -1.8293374, '\\n\\n\\n': -4.8484282}, {'Oh': -1.1750255, 'A': -1.292644, 'Little': -1.7707763}, {' puppy': -1.4710423, ' little': -1.5762535, ' fluffy': -2.0390964}, {' with': -0.9364419, ' full': -1.0321889, ' so': -1.843472}, {' a': -0.94342095, ' teeth': -2.2728543, ' sharp': -2.4661698}, {' mis': -1.0809526, ' curious': -1.462779, ' playful': -2.2151709}, {'ging': -0.011483729, ' in': -4.924625, ' of': -6.336225}, {' tail': -8.363618e-05, ' tale': -9.819708, ' t': -11.518303}, {',\\n': -0.24711426, '\\n': -1.6424733, ',': -4.196024}, {'But': -1.0460274, 'Br': -1.7298996, 'So': -1.7416317}, {'aves': -0.029193752, 'ads': -3.9296777, 'aving': -5.060911}, {' destruction': -0.8494018, ' a': -1.1466849, ' behind': -2.1039221}, {' trail': -0.10101989, ' path': -2.5381498, ' mess': -4.4684935}, {' of': -0.000412796, ' that': -8.831632, ',': -9.255763}, {' destruction': -0.4286536, ' chaos': -1.3567847, ' chew': -3.4325542}, {' and': -0.32978013, ' without': -1.6042018, ' in': -3.2306552}, {' trail': -1.0859507, ' hail': -2.0640545, ' w': -2.6425133}, {'ail': -0.06820376, 'ails': -2.7237384, 'oe': -8.344335}, {'.\\n': -0.20973836, ',\\n': -1.7108561, '\\n': -5.245274}, {'Ch': -1.083026, 'With': -1.6253844, 'He': -2.3932257}]), text='\\n\\nA puppy with a wagging tail,\\nLeaves a path of chaos and wail.\\nWith')], created=1719245286, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=20, prompt_tokens=14, total_tokens=34))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.completions.create(\n",
    "  model = \"gpt-3.5-turbo-instruct\",\n",
    "  prompt = \"Can you write a short poem about puppy who chews up everything?\",\n",
    "  max_tokens = 20,\n",
    "  logprobs = 3,\n",
    "  frequency_penalty = 1\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583e2925",
   "metadata": {
    "id": "583e2925",
    "outputId": "79e6a810-d24b-4c1d-9cdb-fd893b9655bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A puppy with a wagging tail,\n",
      "Leaves a path of chaos and wail.\n",
      "With\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2594ac1",
   "metadata": {
    "id": "b2594ac1",
    "outputId": "32dfbc48-3e2a-42e7-eb24-9cb725153401"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>token_logprobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>-0.205360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>-1.292644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>-1.471042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>-0.936442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>-0.943421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79</td>\n",
       "      <td>-2.323941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83</td>\n",
       "      <td>-0.011484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>87</td>\n",
       "      <td>-0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>92</td>\n",
       "      <td>-0.247114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94</td>\n",
       "      <td>-4.763839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>96</td>\n",
       "      <td>-0.029194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>-1.146685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>102</td>\n",
       "      <td>-2.538150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>107</td>\n",
       "      <td>-0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>110</td>\n",
       "      <td>-1.356785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>116</td>\n",
       "      <td>-0.329780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120</td>\n",
       "      <td>-2.642513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>122</td>\n",
       "      <td>-0.068204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>125</td>\n",
       "      <td>-0.209738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>127</td>\n",
       "      <td>-1.625384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  token_logprobs\n",
       "0     63       -0.205360\n",
       "1     65       -1.292644\n",
       "2     66       -1.471042\n",
       "3     72       -0.936442\n",
       "4     77       -0.943421\n",
       "5     79       -2.323941\n",
       "6     83       -0.011484\n",
       "7     87       -0.000084\n",
       "8     92       -0.247114\n",
       "9     94       -4.763839\n",
       "10    96       -0.029194\n",
       "11   100       -1.146685\n",
       "12   102       -2.538150\n",
       "13   107       -0.000413\n",
       "14   110       -1.356785\n",
       "15   116       -0.329780\n",
       "16   120       -2.642513\n",
       "17   122       -0.068204\n",
       "18   125       -0.209738\n",
       "19   127       -1.625384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text_token_df = pd.DataFrame(data = {\n",
    "    \"text\": response.choices[0].logprobs.text_offset,\n",
    "    \"token_logprobs\": response.choices[0].logprobs.token_logprobs\n",
    "})\n",
    "\n",
    "text_token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8a95ec",
   "metadata": {
    "id": "0e8a95ec",
    "outputId": "f5a45d31-b715-48b6-930b-eb5b98073c0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {'\\n': -1.8293374, '\\n\\n': -0.20535974, '\\n\\n\\n': -4.8484282},\n",
      "    {'A': -1.292644, 'Little': -1.7707763, 'Oh': -1.1750255},\n",
      "    {' fluffy': -2.0390964, ' little': -1.5762535, ' puppy': -1.4710423},\n",
      "    {' full': -1.0321889, ' so': -1.843472, ' with': -0.9364419},\n",
      "    {' a': -0.94342095, ' sharp': -2.4661698, ' teeth': -2.2728543},\n",
      "    {' curious': -1.462779, ' mis': -1.0809526, ' playful': -2.2151709},\n",
      "    {' in': -4.924625, ' of': -6.336225, 'ging': -0.011483729},\n",
      "    {' t': -11.518303, ' tail': -8.363618e-05, ' tale': -9.819708},\n",
      "    {'\\n': -1.6424733, ',': -4.196024, ',\\n': -0.24711426},\n",
      "    {'Br': -1.7298996, 'But': -1.0460274, 'So': -1.7416317},\n",
      "    {'ads': -3.9296777, 'aves': -0.029193752, 'aving': -5.060911},\n",
      "    {' a': -1.1466849, ' behind': -2.1039221, ' destruction': -0.8494018},\n",
      "    {' mess': -4.4684935, ' path': -2.5381498, ' trail': -0.10101989},\n",
      "    {' of': -0.000412796, ' that': -8.831632, ',': -9.255763},\n",
      "    {' chaos': -1.3567847, ' chew': -3.4325542, ' destruction': -0.4286536},\n",
      "    {' and': -0.32978013, ' in': -3.2306552, ' without': -1.6042018},\n",
      "    {' hail': -2.0640545, ' trail': -1.0859507, ' w': -2.6425133},\n",
      "    {'ail': -0.06820376, 'ails': -2.7237384, 'oe': -8.344335},\n",
      "    {'\\n': -5.245274, ',\\n': -1.7108561, '.\\n': -0.20973836},\n",
      "    {'Ch': -1.083026, 'He': -2.3932257, 'With': -1.6253844}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "pp.pprint(response.choices[0].logprobs.top_logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4981b86",
   "metadata": {
    "id": "f4981b86"
   },
   "source": [
    "### Streaming\n",
    "\n",
    "The OpenAI API provides the ability to stream responses back to a client in order to allow partial results for certain requests. To achieve this, we follow the Server-sent events standard.\n",
    "\n",
    "https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events\n",
    "\n",
    "Should be able to see the content streaming in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2df9643",
   "metadata": {
    "id": "f2df9643",
    "outputId": "e471abda-664b-4721-8435-df285ce870c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unraveling the Factors Behind the Fall of Enron\n",
      "\n",
      "The fall of Enron shook the business world at the dawn of the 21st century, quickly becoming one of the most infamous corporate collapses in history. Once ranked as America's seventh-largest company with an estimated market value of $68 billion at its peak, Enron suddenly came crumbling down. This article will explore the causes that led to the spectacular fall of this energy giant. \n",
      "\n",
      "1. Accounting Fraud\n",
      "\n",
      "Without a doubt, Enron's accounting practices played an instrumental role in its downfall. The company used complex accounting methods, crafted by its chief financial officer Andrew Fastow, to hide debts and inflate profits. 'Special Purpose Entities' (SPEs) were created to mislead investors and credit-rating agencies, showing a more robust financial performance than the actual. When the extent of its debt burden and the true state of its finances were revealed, investor confidence rapidly disintegrated, resulting in a sudden crash of its stock. \n",
      "\n",
      "2. Lack of Transparency and Integrity\n",
      "\n",
      "The culture in Enron was rooted in deception. Executives exploited loopholes in the system to conceal the company's financial realities, projecting an illusion of unprecedented prosperity. They manipulated the market by presenting false trades to create the illusion of high energy demand and high profits. Lack of openness and accountability created an environment where unethical behaviors were nurtured. Employees were encouraged to engage in questionable practices with bonuses tied to their ability to hit financial targets, regardless of the means.\n",
      "\n",
      "3. Poor Business Model\n",
      "\n",
      "Another factor behind Enron's collapse was its flawed business model. Initially, Enron's operations were centered around the supply of gas and electricity. However, under the leadership of CEO Jeffrey Skilling, it transformed itself into a diversified conglomerate dealing with energy trading and high-risk ventures such as telecommunications, internet services, and water companies. These non-core ventures required substantial capital investments, but many proved unsuccessful and drained the company's resources.\n",
      "\n",
      "4. Regulatory Failures\n",
      "\n",
      "The collapse of Enron also exposed serious shortcomings in regulation and enforcement. Over many years, Enron used aggressive lobbying strategies to win deregulation in the energy markets. This opened the door for the company to set its own prices and exploit the lack of oversight – causing an artificial power shortage that led to the infamous California energy crisis in 2000-2001. \n",
      "\n",
      "5. Ethical Erosion and Corporate Governance\n",
      "\n",
      "Lastly, Enron's fall was a result of a systematic erosion of ethical standards and corporate governance. Companies exist within a broader ecosystem, where trust between the company, its shareholders, employees, and regulators plays a crucial role in driving sustainable growth. Enron's culture, however, was characterized by a lack of ethics and transparency, leading to rampant mismanagement and fraudulent activities. \n",
      "\n",
      "In conclusion, Enron's fall was the result of a lethal mix of fraudulent accounting, lack of transparency, a flawed business model, regulatory failures, and widespread ethical erosion. A failure at such a colossal scale serves as a stern reminder of what a lack of integrity and mismanagement can lead to in the corporate world. Lessons from Enron's collapse should continue to guide corporate governance and regulatory policies to prevent similar occurrences in the future."
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please write an article on the causes of the fall of Enron\"\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f1281",
   "metadata": {
    "id": "905f1281"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f57b8f",
   "metadata": {
    "id": "70f57b8f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff4e81",
   "metadata": {
    "id": "aeff4e81"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eebd471",
   "metadata": {
    "id": "8eebd471"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbff196",
   "metadata": {
    "id": "bcbff196"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f22093",
   "metadata": {
    "id": "c6f22093"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c51a67",
   "metadata": {
    "id": "20c51a67"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "openai_apis_venv",
   "language": "python",
   "name": "openai_apis_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
